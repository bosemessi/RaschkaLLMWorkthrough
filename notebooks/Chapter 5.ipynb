{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fea56eb-045a-4ea9-b68c-13bbc3c21c49",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "### Imports \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "from GPT_classes import GPTModel\n",
    "from utils import generate_text_simple, text_to_token_ids, token_ids_to_text\n",
    "from dataloaders import create_dataloader_v1\n",
    "from loss_functions import calc_loss_batch, calc_loss_loader, plot_losses\n",
    "from training import train_model_simple, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89942a8c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 256,  # Context length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n_heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False        # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2042b0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49287061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d04e4",
   "metadata": {},
   "source": [
    "## The training dataset - The Verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16413157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "    \n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22779d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train-validation 90-10 split\n",
    "\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b52dad0",
   "metadata": {
    "code_folding": [
     2,
     11
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7f29f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)   \n",
    "with torch.no_grad():                                        \n",
    "    train_loss = calc_loss_loader(train_loader, model, device)    \n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd14e2f",
   "metadata": {},
   "source": [
    "## Section 5.2 : Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857fa213",
   "metadata": {
    "code_folding": [
     5,
     11
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
      "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
      "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
      "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
      "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
      "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
      "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
      "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
      "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
      "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
      "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
      "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "### 10 epochs\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "     model.parameters(),           \n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9adae0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f81ad",
   "metadata": {},
   "source": [
    "## 5.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3853b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9414f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad4e0bf",
   "metadata": {},
   "source": [
    "### The above generation is deterministic. Can be made probabilistic with temperature-scaling of the logits, then sampling via multinomial, and also combining with top-K to not give importance to all tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "005b23ec",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aed0fa",
   "metadata": {},
   "source": [
    "## Section 5.4 Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9b1d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### recommended to save both model and optimizer states\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"../model/model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62424b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### reloading\n",
    "\n",
    "checkpoint = torch.load(\"../model/model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a9c6bf",
   "metadata": {},
   "source": [
    "## Section 5.5 : Loading pre-trained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2c811ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 18:37:16.436208: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb7f5f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|███████████████████████████| 77.0/77.0 [00:00<00:00, 13.5kiB/s]\n",
      "encoder.json: 100%|████████████████████████| 1.04M/1.04M [00:04<00:00, 242kiB/s]\n",
      "hparams.json: 100%|█████████████████████████| 90.0/90.0 [00:00<00:00, 10.0kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|████████| 498M/498M [40:48<00:00, 203kiB/s]\n",
      "model.ckpt.index: 100%|███████████████████| 5.21k/5.21k [00:00<00:00, 1.15MiB/s]\n",
      "model.ckpt.meta: 100%|███████████████████████| 471k/471k [00:02<00:00, 195kiB/s]\n",
      "vocab.bpe: 100%|█████████████████████████████| 456k/456k [00:02<00:00, 212kiB/s]\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5786ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7b60c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c01fa771",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02eb8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01e4944e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f157f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                          \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fc87fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbb2d363",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):     #2\n",
    "        q_w, k_w, v_w = np.split(                            #3\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "774e19f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ab8915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e90f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_bazinga",
   "language": "python",
   "name": "pytorch_bazinga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
