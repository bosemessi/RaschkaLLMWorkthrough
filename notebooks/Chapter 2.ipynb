{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fe9cc1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb8cf3a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65902b9c",
   "metadata": {},
   "source": [
    "### Section 2.2 : Tokenization -> will work by first splitting the text on all sorts of punctuations and whitespaces, and dropping the whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f852d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3544179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc1d21",
   "metadata": {},
   "source": [
    "## Section 2.3 : Tokens to Token IDs -> take all unique items in the preprocessed text, sort, then create a dict of item to item index in the sorted list. We can then create complete tokenizer classes by using these vocabs as input. It will have a function to encode the text using the vocab dict, and a function to decode a list of ids to the corresponding text using the inverse dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec11035c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc2aecf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, '\"': 1, \"'\": 2, '(': 3, ')': 4, ',': 5, '--': 6, '.': 7, ':': 8, ';': 9, '?': 10, 'A': 11, 'Ah': 12, 'Among': 13, 'And': 14, 'Are': 15, 'Arrt': 16, 'As': 17, 'At': 18, 'Be': 19, 'Begin': 20, 'Burlington': 21, 'But': 22, 'By': 23, 'Carlo': 24, 'Chicago': 25, 'Claude': 26, 'Come': 27, 'Croft': 28, 'Destroyed': 29, 'Devonshire': 30, 'Don': 31, 'Dubarry': 32, 'Emperors': 33, 'Florence': 34, 'For': 35, 'Gallery': 36, 'Gideon': 37, 'Gisburn': 38, 'Gisburns': 39, 'Grafton': 40, 'Greek': 41, 'Grindle': 42, 'Grindles': 43, 'HAD': 44, 'Had': 45, 'Hang': 46, 'Has': 47, 'He': 48, 'Her': 49, 'Hermia': 50}\n"
     ]
    }
   ],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "print({k:v for k,v in vocab.items() if v<51})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e826e25b",
   "metadata": {},
   "source": [
    "#### Complete tokenizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f160f7f5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab            \n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}        \n",
    "\n",
    "    def encode(self, text):      \n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):         \n",
    "        text = \" \".join([self.int_to_str[i] for i in ids]) \n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)    \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ba69a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab = vocab) \n",
    "text = '''\n",
    "    \"It's the last he painted, you know,\" \n",
    "       Mrs. Gisburn said with pardonable pride.\n",
    "'''\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4265da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96875b12",
   "metadata": {},
   "source": [
    "## Section 2.4 : Adding special context tokens -> extend the vocab by adding tokens for unknown texts and end of texts. Otherwise the dict call will error out for unknown texts (text that does not exist in the vocab natively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f42590c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c13904a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'your': 1128, 'yourself': 1129, '<|endoftext|>': 1130, '<|unk|>': 1131}\n"
     ]
    }
   ],
   "source": [
    "print({k:v for k,v in vocab.items() if v > len(vocab.items())-5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d173e0",
   "metadata": {},
   "source": [
    "#### New Tokenizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f39b5acc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab            \n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}        \n",
    "\n",
    "    def encode(self, text):      \n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):         \n",
    "        text = \" \".join([self.int_to_str[i] for i in ids]) \n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)    \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6291986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffec2c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03d0dfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c212303",
   "metadata": {},
   "source": [
    "## Section 2.5 : Byte pair encoding -> this can deal with any unknown word by splitting into smaller subtokens (could be single characters, combination of characters etc depending upon their frequency of usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1526a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b9e6e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n",
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)\n",
    "\n",
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e945975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33901, 86, 343, 86, 220, 959]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text=\"Akwirw ier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b52423c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Akwirw ier'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text=\"Akwirw ier\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e9ebf",
   "metadata": {},
   "source": [
    "#### In short, BPE builds its vocabulary by iteratively merging frequent characters into subwords and frequent subwords into words. For example, BPE starts with adding all individual single characters to its vocabulary (“a,” “b,” etc.). In the next stage, it merges character combinations that frequently occur together into subwords. For example, “d” and “e” may be merged into the subword “de,” which is common in many English words like “define,” “depend,” “made,” and “hidden.” The merges are determined by a frequency cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93feb42a",
   "metadata": {},
   "source": [
    "## Section 2.6 : Data sampling with a sliding window - LLMs learn to predict the next word, one word at a time. So create input-target pairs for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f240b21",
   "metadata": {},
   "source": [
    "####  Let's encode the raw text using BPE first and take a sample by removing the first 50 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43918d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))\n",
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948aeed",
   "metadata": {},
   "source": [
    "#### We need to work with texts of a certain context size (context will help define meaning to the sentences/phrases). Let's say context size is 4. Then our input container \"x\" is a collection of 4 consective text items, while the target container \"y\" is the same but shifted by one position to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9f9486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4         \n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42a542",
   "metadata": {},
   "source": [
    "#### For each such input-target pair, we can then set up the next word prediction task by iterating over, appending one item at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf1190a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff5fca1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9381290",
   "metadata": {},
   "source": [
    "#### Wrapping everything above into a single dataloader class that will \n",
    "    - take as input the text, the tokenizer, the context size(max length) and a stride parameter\n",
    "    - tokenize the text\n",
    "    - then iterate over the token ids to create the input and output container tensors\n",
    "    - with additional functions to return len of the inputs and input-target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acc794e8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)    \n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):     \n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):    \n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):         \n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "945656ce",
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def create_dataloader_v1(\n",
    "    txt, \n",
    "    batch_size=4, \n",
    "    max_length=256,\n",
    "    stride=128, \n",
    "    shuffle=True, \n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    "):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")                         \n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)   \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,     \n",
    "        num_workers=num_workers     \n",
    "    )\n",
    "    ### drop_last=True drops the last batch if it is shorter \n",
    "    ### than the specified batch_size to prevent loss spikes during training.\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "559df6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n",
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, \n",
    "    batch_size=1, \n",
    "    max_length=4, \n",
    "    stride=1, \n",
    "    shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)     \n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)\n",
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738b2b7",
   "metadata": {},
   "source": [
    "##### The above makes the stride parameter clear : the input shifts by the stride amount, here = 1, from one batch to the next.Test out below with different context sizes and stride values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "580ca394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 40, 367]]), tensor([[ 367, 2885]])]\n",
      "[tensor([[2885, 1464]]), tensor([[1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, \n",
    "    batch_size=1, \n",
    "    max_length=2, \n",
    "    stride=2, \n",
    "    shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)     \n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)\n",
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2849176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464, 1807, 3619,  402,  271]]), tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899]])]\n",
      "[tensor([[ 1807,  3619,   402,   271, 10899,  2138,   257,  7026]]), tensor([[ 3619,   402,   271, 10899,  2138,   257,  7026, 15632]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, \n",
    "    batch_size=1, \n",
    "    max_length=8, \n",
    "    stride=4, \n",
    "    shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)     \n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)\n",
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a06e333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now experiment with batch size as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "017112eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 2885,  1464,  1807,  3619],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [  402,   271, 10899,  2138],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [  257,  7026, 15632,   438],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [ 2016,   257,   922,  5891]])\n",
      "\n",
      "Targets:\\n tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 1464,  1807,  3619,   402],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [  271, 10899,  2138,   257],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [ 7026, 15632,   438,  2016],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [  257,   922,  5891,  1576]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=4, stride=2,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc368e",
   "metadata": {},
   "source": [
    "#### In the above, there are batch_size number of rows in input and target (here = 8). For each corresponding row, target is shifted by 1 position compared to input. The stride determines the shift between consecutive rows of inputs (here = 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd696416",
   "metadata": {},
   "source": [
    "## Section 2.7 : Creating token embeddings -> use torch.nn.Embedding on the vocab size and chosen output dimension of embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba3e977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f259ba6",
   "metadata": {},
   "source": [
    "#### In this toy example, there are 6 possible tokens as determined by vocab_size, and we have chosen each embedding vector to have a dimension of 3 as determined by output_dim. Hence, the torch.nn.Embedding creates a randomized tensor of shape = vocab_size * output_dim, representing each of these token embedding vectors. So a token id = 2 will correspond to the third row of this tensor, as verified below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8765a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8ee75d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38443a",
   "metadata": {},
   "source": [
    "## Section 2.8 Encoding word positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19a4633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9526c2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\\n torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "   stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a065a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c412697f",
   "metadata": {},
   "source": [
    "#### Absolute positional encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b189110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "458b294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd8301",
   "metadata": {},
   "source": [
    "## To summarize : \n",
    "- read text file and convert to tokens\n",
    "- create token id to token dictionary and reverse as well.\n",
    "- Use torch to create token embedding vectors using vocab size and chosen output dimension of vectors\n",
    "- self-attention is position-agnostic, so same tokens from different parts of the text have same embedding vectors. We can create positional embedding vectors.\n",
    "- absolute positional embedding and relative positional embeddings.\n",
    "- add the token embedding vector to positional embedding vector to create the final input embeddings, which will be a tensor of dimensions = batch_size * context size * output dim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a8a72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_bazinga",
   "language": "python",
   "name": "pytorch_bazinga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
